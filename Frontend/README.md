## Title of the Project
AI-Powered Automated Multilingual Video Translation and Integration System.

## About
This project aims to create a sophisticated Full Stack web application that automatically translates audio in videos, enhancing accessibility for diverse linguistic audiences. The application features a dynamic frontend and an efficient backend, ensuring smooth user interactions. It extracts audio from videos and reintegrates translated audio seamlessly. Users can upload videos, select target languages, and download updated versions with translated audio. The application also manages translated files securely and employs authentication to protect user data. By addressing language barriers in multimedia, this platform expands the reach of video content to a global audience, providing an intuitive and scalable solution.

## Features
- Robust Authentication System
- Seamless Integration of Translated Audio
- Enhancing Linguistic Precision
- Improved Real-Time Processing
- Leveraging Comprehensive Multilingual Datasets

## Requirements
* Operating System: Requires a 64-bit OS (Windows 10 or Ubuntu) for compatibility with deep learning frameworks.
* Development Environment: Vercel
* Web Frameworks: React.js, Node.js/Express.JS
* Cloud Storage: MongoDB, Firebase
* Multimedia Processing: ffmpeg
* Version Control: Implementation of Git for collaborative development and effective code management.
* IDE: Use of VSCode as the Integrated Development Environment for coding, debugging, and version control integration.

## System Architecture



## Output


## Results and Impact
The video translation system addresses the growing need for accessible multimedia content across languages, making it essential for users to understand video in their native language as globalization connects diverse audiences. With features like user authentication, video management, audio extraction, speech-to-text conversion, and text translation, it provides a seamless experience. Leveraging advanced technologies, the system ensures high-quality translations that accurately convey the original message, all through a user-friendly interface that simplifies uploads and file management while prioritizing data security. Serving educators, content creators, and businesses, this innovative solution bridges language gaps and promotes inclusivity in digital communication, adapting to user feedback and advancements to maintain its leadership in the field.

## Articles published / References
1. M. A. Zagot and V. V. Vozdvizhensky, "Translating Video: Obstacles and Challenges," Procedia - Social and Behavioral Sciences, vol. 154, pp. 268–271, 2014. doi: 10.1016/j.sbspro.2014.10.149.
2. J. Matoušek and J. Vít, "Improving Automatic Dubbing with Subtitle Timing Optimization Using Video Cut Detection," Faculty of Applied Sciences, Dept. of Cybernetics, 2012.
3. K. Ning, M. Cai, D. Xie, and F. Wu, "An Attentive Sequence-to-Sequence Translator for Localizing Video Clips by Natural Language," IEEE Transactions on Multimedia, vol. 22, no. 9, pp. 2434–2443, 2020. doi: 10.1109/tmm.2019.2957854.
4. N. S. Kurian et al., "AI-Enabled Dubbing Software for Multilingual Content Localization," African Journal of BioSciences, vol. 6, no. 10, pp. 924–929,2024.doi: 10.33472/AFJBS.6.10.2024.924-929.
5. W. Wang, X. Zhang, and Y. Li, "VATEX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research," arXiv preprint, 2020.